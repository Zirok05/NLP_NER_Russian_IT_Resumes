import json
from pathlib import Path


def extract_text_from_resume(resume_json):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ –æ–±—ä–µ–∫—Ç–∞ —Ä–µ–∑—é–º–µ HH.ru"""
    parts = []
    data = resume_json

    # 1. –§–ò–û –∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫
    name_parts = [data.get('last_name'), data.get('first_name'), data.get('middle_name')]
    full_name = ' '.join([n for n in name_parts if n])
    if full_name:
        parts.append(f"–ö–∞–Ω–¥–∏–¥–∞—Ç: {full_name}")
    if data.get('title'):
        parts.append(f"–¶–µ–ª–µ–≤–∞—è –¥–æ–ª–∂–Ω–æ—Å—Ç—å: {data['title']}")
    parts.append("")

    # 2. –†–∞–∑–¥–µ–ª "–û–±–æ –º–Ω–µ"
    if data.get('skills'):
        parts.append("–û–ë–û –ú–ù–ï:")
        parts.append(data['skills'])
        parts.append("")

    # 3. –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã
    if data.get('experience') and isinstance(data['experience'], list):
        parts.append("–û–ü–´–¢ –†–ê–ë–û–¢–´:")
        for exp in data['experience']:
            position = exp.get('position', '–î–æ–ª–∂–Ω–æ—Å—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞')
            company = exp.get('company', '–ö–æ–º–ø–∞–Ω–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω–∞')
            start = exp.get('start', '')
            end = exp.get('end', '–ø–æ –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è')
            duration = f" ({start} ‚Äî {end})" if start else ""
            exp_line = f"- {position}, {company}{duration}"
            parts.append(exp_line)

            description = exp.get('description')
            if description:
                parts.append(f"  {description}")
        parts.append("")

    # 4. –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
    if data.get('education'):
        parts.append("–û–ë–†–ê–ó–û–í–ê–ù–ò–ï:")
        edu = data['education']
        for higher in edu.get('higher', []):
            name = higher.get('name', '')
            year = higher.get('year', '')
            if name:
                edu_line = f"- {name}"
                if year:
                    edu_line += f" ({year} –≥.)"
                parts.append(edu_line)
        parts.append("")

    # 5. –ù–∞–≤—ã–∫–∏
    if data.get('skill_set'):
        parts.append(f"–ö–õ–Æ–ß–ï–í–´–ï –ù–ê–í–´–ö–ò: {', '.join(data['skill_set'])}")

    return "\n".join(parts)


def save_resumes_from_json(json_file, output_folder):
    """
    –ß–∏—Ç–∞–µ—Ç JSON —Å hh.ru, –ø—Ä–∏–º–µ–Ω—è–µ—Ç extract_text_from_resume,
    —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ .txt –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π JSON –≤ *_use.json
    """
    json_path = Path(json_file)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º JSON
    with open(json_path, 'r', encoding='utf-8') as f:
        resumes = json.load(f)

    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(resumes)} —Ä–µ–∑—é–º–µ –∏–∑ {json_path.name}")

    # –°–æ–∑–¥–∞—ë–º –≤—ã—Ö–æ–¥–Ω—É—é –ø–∞–ø–∫—É, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    output_path = Path(output_folder)
    output_path.mkdir(parents=True, exist_ok=True)

    for i, resume in enumerate(resumes):
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
        text = extract_text_from_resume(resume.get('raw', resume))

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ .txt
        resume_id = resume.get('id', f"resume_{i:04d}")
        filepath = output_path / f"{resume_id}.txt"

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(text)

        if (i + 1) % 10 == 0:
            print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {i + 1}/{len(resumes)}")

    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π JSON
    new_json_path = json_path.with_name(json_path.stem + "_used" + json_path.suffix)
    json_path.rename(new_json_path)

    print(f"\n–ì–æ—Ç–æ–≤–æ! {len(resumes)} —Ñ–∞–π–ª–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {output_folder}")
    print(f"JSON –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω –≤: {new_json_path.name}")


import hashlib
from pathlib import Path


def deduplicate_txt_folder(folder_path):
    """
    –ü—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ –í–°–ï–ú .txt —Ñ–∞–π–ª–∞–º –≤ –ø–∞–ø–∫–µ –∏ —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
    """
    folder = Path(folder_path)
    if not folder.exists():
        print(f"–ü–∞–ø–∫–∞ {folder_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ .txt —Ñ–∞–π–ª—ã
    txt_files = list(folder.glob("*.txt"))
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(txt_files)} .txt —Ñ–∞–π–ª–æ–≤")

    # –°–ª–æ–≤–∞—Ä—å: —Ö—ç—à -> –∏–º—è –ø–µ—Ä–≤–æ–≥–æ —Ñ–∞–π–ª–∞
    unique_hashes = {}
    duplicates_count = 0
    kept_count = 0

    for filepath in sorted(txt_files):  # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç–∏
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()

        # –°–æ–∑–¥–∞—ë–º —Ö—ç—à –æ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ (–±–µ–∑ —É—á—ë—Ç–∞ –ø—Ä–æ–±–µ–ª–æ–≤ –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞)
        clean_content = ' '.join(content.lower().split())
        content_hash = hashlib.md5(clean_content.encode()).hexdigest()

        if content_hash in unique_hashes:
            # –î—É–±–ª–∏–∫–∞—Ç ‚Äî —É–¥–∞–ª—è–µ–º
            filepath.unlink()
            duplicates_count += 1
            print(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω –¥—É–±–ª–∏–∫–∞—Ç: {filepath.name} (—Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å {unique_hashes[content_hash]})")
        else:
            # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ‚Äî –∑–∞–ø–æ–º–∏–Ω–∞–µ–º
            unique_hashes[content_hash] = filepath.name
            kept_count += 1

    print(f"\n–ò—Ç–æ–≥–∏:")
    print(f"–û—Å—Ç–∞–≤–ª–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {kept_count}")
    print(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count}")
    print(f"–ü–∞–ø–∫–∞: {folder.absolute()}")

    return kept_count, duplicates_count


import json
from pathlib import Path


def create_label_studio_json(txt_folder="resumes_json/converted",
                             output_folder="resumes_json/for_label_studio"):
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –í–°–ï .txt –∏–∑ converted/ –≤ –æ–¥–∏–Ω JSON –¥–ª—è Label Studio
    """
    txt_folder = Path(txt_folder)
    output_folder = Path(output_folder)


    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ .txt —Ñ–∞–π–ª—ã
    txt_files = list(txt_folder.glob("*.txt"))
    total_files = len(txt_files)

    print(f"–ù–∞–π–¥–µ–Ω–æ {total_files} .txt —Ñ–∞–π–ª–æ–≤")

    if total_files == 0:
        print("–ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return

    # –°–æ–∑–¥–∞—ë–º –æ–¥–∏–Ω –±–æ–ª—å—à–æ–π JSON
    tasks = []
    for txt_file in txt_files:
        with open(txt_file, 'r', encoding='utf-8') as f:
            text = f.read()

        tasks.append({
            "data": {
                "text": text,
                "source": txt_file.name
            }
        })

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_file = output_folder / f"label_studio_all_{total_files}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(tasks, f, ensure_ascii=False, indent=2)

    print(f"JSON —Ñ–∞–π–ª: {output_file.name} ({total_files} —Ä–µ–∑—é–º–µ)")
    print(f"–ü—É—Ç—å: {output_file.absolute()}")




# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
#save_resumes_from_json("resumes_json/raw/it_resumes_20260226_153906.json", "resumes_json/converted")

# deduplicate_txt_folder("resumes_json/converted")
#
# create_label_studio_json()