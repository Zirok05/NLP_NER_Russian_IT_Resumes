{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8e1b4f2-473b-42d0-b98b-b856c3015b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import random\n",
    "\n",
    "def read_jsonl_dataset(file_path):\n",
    "    \"\"\"Чтение JSONL датасета \"\"\"\n",
    "    sentences = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line.strip())\n",
    "            tokens = item['tokens']\n",
    "            ner_tags = item['ner_tags']\n",
    "            \n",
    "            # Создаем предложение в формате (word, tag)\n",
    "            sentence = [(token, tag) for token, tag in zip(tokens, ner_tags)]\n",
    "            sentences.append(sentence)\n",
    "    \n",
    "    print(f\"Загружено {len(sentences)} предложений из JSONL файла\")\n",
    "    return sentences\n",
    "\n",
    "def create_label_mapping(sentences):\n",
    "    \"\"\"Создание mapping между метками и ID\"\"\"\n",
    "    all_labels = set()\n",
    "    for sentence in sentences:\n",
    "        for word, label in sentence:\n",
    "            all_labels.add(label)\n",
    "    \n",
    "    # Сортируем метки, начиная с 'O'\n",
    "    label_list = ['O'] + sorted([l for l in all_labels if l != 'O'])\n",
    "    label2id = {label: i for i, label in enumerate(label_list)}\n",
    "    id2label = {i: label for label, i in label2id.items()}\n",
    "    \n",
    "    print(f\"Найдено {len(label_list)} меток: {label_list}\")\n",
    "    return label2id, id2label, label_list\n",
    "\n",
    "def align_labels_with_tokens(word_ids, labels):\n",
    "    \"\"\"Выравнивает метки с токенами\"\"\"\n",
    "    aligned_labels = []\n",
    "    previous_word_idx = None\n",
    "    \n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            aligned_labels.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            aligned_labels.append(labels[word_idx])\n",
    "        else:\n",
    "            aligned_labels.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "    \n",
    "    return aligned_labels\n",
    "\n",
    "def create_sliding_windows_complete(words, labels, tokenizer, window_size=510, stride=256):\n",
    "    \"\"\"Создает перекрывающиеся окна, сохраняя все части текста\"\"\"\n",
    "    \n",
    "    # Токенизируем весь текст \n",
    "    encoding = tokenizer(\n",
    "        words,\n",
    "        is_split_into_words=True,\n",
    "        truncation=False,\n",
    "        padding=False,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    \n",
    "    full_tokens = encoding['input_ids']\n",
    "    word_ids = encoding.word_ids()\n",
    "    \n",
    "    # Если текст короткий - возвращаем как есть\n",
    "    if len(full_tokens) <= window_size:\n",
    "        aligned_labels = align_labels_with_tokens(word_ids, labels)\n",
    "        return [(full_tokens, aligned_labels)]\n",
    "    \n",
    "    windows = []\n",
    "    \n",
    "    # Создаем перекрывающиеся окна до самого конца\n",
    "    start_idx = 0\n",
    "    while start_idx < len(full_tokens):\n",
    "        end_idx = min(start_idx + window_size, len(full_tokens))\n",
    "        \n",
    "        # Cохраняем все окна, даже короткие в конце\n",
    "        window_tokens = full_tokens[start_idx:end_idx]\n",
    "        window_word_ids = word_ids[start_idx:end_idx]\n",
    "        \n",
    "        # Выравниваем метки для этого окна\n",
    "        window_labels = []\n",
    "        previous_word_idx = None\n",
    "        \n",
    "        for word_idx in window_word_ids:\n",
    "            if word_idx is None:\n",
    "                window_labels.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                window_labels.append(labels[word_idx])\n",
    "            else:\n",
    "                window_labels.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        windows.append((window_tokens, window_labels))\n",
    "        \n",
    "        if end_idx == len(full_tokens):\n",
    "            break\n",
    "            \n",
    "        # Сдвигаем окно\n",
    "        start_idx += stride\n",
    "        \n",
    "        # Гарантируем, что последнее окно захватывает конец текста\n",
    "        if start_idx + window_size >= len(full_tokens) and start_idx < len(full_tokens):\n",
    "            start_idx = max(0, len(full_tokens) - window_size)\n",
    "    \n",
    "    #print(f\"Создано {len(windows)} окон для текста из {len(full_tokens)} токенов\")\n",
    "    return windows\n",
    "\n",
    "def prepare_dataset_with_sliding_windows(jsonl_file_path, tokenizer, window_size=510, stride=256, val_fraction=0.2):\n",
    "    \"\"\"Делит датасет на окна, а затем на трейн и валидацию, гарантируя, \n",
    "        что все окна одного документа будут только в одной из двух частей\"\"\"\n",
    "    \n",
    "    print(\"Подготовка данных с перекрывающимися окнами...\")\n",
    "    \n",
    "    # 1. Чтение данных\n",
    "    sentences = read_jsonl_dataset(jsonl_file_path)\n",
    "    print(f\"Загружено {len(sentences)} исходных документов\")\n",
    "    \n",
    "    # 2. Создание mapping меток\n",
    "    label2id, id2label, label_list = create_label_mapping(sentences)\n",
    "    \n",
    "    # 3. Нарезаем на окна, сохраняем индекс документа\n",
    "    all_windows = []\n",
    "    all_labels = []\n",
    "    doc_indices = []  # Для каждого окна храним индекс документа\n",
    "    \n",
    "    stats = {\n",
    "        'total_docs': len(sentences),\n",
    "        'windows_per_doc': []\n",
    "    }\n",
    "    \n",
    "    for doc_idx, sentence in enumerate(sentences):\n",
    "        words = [word for word, label in sentence]\n",
    "        label_ids = [label2id[label] for word, label in sentence]\n",
    "        \n",
    "        # Создаем окна для этого документа\n",
    "        windows = create_sliding_windows_complete(words, label_ids, tokenizer, window_size, stride)\n",
    "        \n",
    "        # Сохраняем каждое окно с индексом документа\n",
    "        for window_tokens, window_labels in windows:\n",
    "            all_windows.append(window_tokens)\n",
    "            all_labels.append(window_labels)\n",
    "            doc_indices.append(doc_idx)\n",
    "        \n",
    "        stats['windows_per_doc'].append(len(windows))\n",
    "    \n",
    "    total_windows = len(all_windows)\n",
    "    print(f\"\\nСтатистика по окнам:\")\n",
    "    print(f\"Всего окон: {total_windows}\")\n",
    "    print(f\"Среднее число окон на документ: {sum(stats['windows_per_doc'])/len(sentences):.1f}\")\n",
    "    print(f\"Мин/макс окон на документ: {min(stats['windows_per_doc'])} / {max(stats['windows_per_doc'])}\")\n",
    "    \n",
    "    # 4. Набираем валидацию целыми документами\n",
    "    target_val_windows = int(total_windows * val_fraction)\n",
    "    print(f\"\\nЦелевой размер валидации: {target_val_windows} окон ({val_fraction*100:.0f}%)\")\n",
    "    \n",
    "    # Получаем уникальные индексы документов и перемешиваем\n",
    "    unique_docs = list(set(doc_indices))\n",
    "    random.seed(42)\n",
    "    random.shuffle(unique_docs)\n",
    "    \n",
    "    # Набираем документы в валидацию, пока не достигнем цели\n",
    "    val_doc_indices = set()\n",
    "    val_windows_count = 0\n",
    "    docs_used = []\n",
    "    \n",
    "    for doc_idx in unique_docs:\n",
    "        # Сколько окон дает этот документ\n",
    "        doc_window_count = stats['windows_per_doc'][doc_idx]\n",
    "\n",
    "        # Проверяем, что с добавлением документа, \n",
    "        # число окон не будет превышать требуемое более, чем на 10%\n",
    "        if val_windows_count + doc_window_count <= target_val_windows * 1.1:  \n",
    "            val_doc_indices.add(doc_idx)\n",
    "            val_windows_count += doc_window_count\n",
    "            docs_used.append(doc_idx)\n",
    "            #print(f\"Добавлен документ {doc_idx}: +{doc_window_count} окон (всего: {val_windows_count}/{target_val_windows})\")\n",
    "        \n",
    "        if val_windows_count >= target_val_windows:\n",
    "            break\n",
    "    \n",
    "    # Остальные документы - в train\n",
    "    train_doc_indices = set(unique_docs) - val_doc_indices\n",
    "    \n",
    "    print(f\"\\nИтоговое разделение:\")\n",
    "    print(f\"Train: {len(train_doc_indices)} документов\")\n",
    "    print(f\"Validation: {len(val_doc_indices)} документов\")\n",
    "    \n",
    "    # Собираем окна для train и validation\n",
    "    train_indices = [i for i, doc_idx in enumerate(doc_indices) if doc_idx in train_doc_indices]\n",
    "    val_indices = [i for i, doc_idx in enumerate(doc_indices) if doc_idx in val_doc_indices]\n",
    "    \n",
    "    print(f\"Train окон: {len(train_indices)} ({len(train_indices)/total_windows*100:.1f}%)\")\n",
    "    print(f\"Validation окон: {len(val_indices)} ({len(val_indices)/total_windows*100:.1f}%)\")\n",
    "    \n",
    "    # Проверка на утечку\n",
    "    train_docs_in_val = set([doc_indices[i] for i in train_indices]) & set([doc_indices[i] for i in val_indices])\n",
    "    print(f\"\\nПроверка на утечку: {'Утечка' if train_docs_in_val else 'Всё хорошо'}\")\n",
    "    \n",
    "    # 5. Создание датасетов\n",
    "    train_encodings = {\n",
    "        'input_ids': [all_windows[i] for i in train_indices],\n",
    "        'attention_mask': [[1] * len(all_windows[i]) for i in train_indices],\n",
    "        'labels': [all_labels[i] for i in train_indices]\n",
    "    }\n",
    "    \n",
    "    val_encodings = {\n",
    "        'input_ids': [all_windows[i] for i in val_indices],\n",
    "        'attention_mask': [[1] * len(all_windows[i]) for i in val_indices],\n",
    "        'labels': [all_labels[i] for i in val_indices]\n",
    "    }\n",
    "    \n",
    "    train_dataset = Dataset.from_dict(train_encodings)\n",
    "    val_dataset = Dataset.from_dict(val_encodings)\n",
    "    \n",
    "    dataset = DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'validation': val_dataset\n",
    "    })\n",
    "    \n",
    "    return dataset, label2id, id2label, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dd32260-9a17-4c3b-ab24-859ec17a45a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Устройство: mps\n",
      "\n",
      "Оценка модели group1...\n",
      "Модель: /Users/artemzmailov/Desktop/NER_IT_Resumes_Project/models/model_1_final\n",
      "Датасет: /Users/artemzmailov/Desktop/NER_IT_Resumes_Project/datasets/group1_dataset.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подготовка данных с перекрывающимися окнами...\n",
      "Загружено 307 предложений из JSONL файла\n",
      "Загружено 307 исходных документов\n",
      "Найдено 13 меток: ['O', 'B-DEGREE', 'B-LINKS', 'B-LOCATION', 'B-METRICS', 'B-POSITIONS', 'B-TIME', 'I-DEGREE', 'I-LINKS', 'I-LOCATION', 'I-METRICS', 'I-POSITIONS', 'I-TIME']\n",
      "\n",
      "Статистика по окнам:\n",
      "Всего окон: 9785\n",
      "Среднее число окон на документ: 31.9\n",
      "Мин/макс окон на документ: 1 / 366\n",
      "\n",
      "Целевой размер валидации: 1957 окон (20%)\n",
      "\n",
      "Итоговое разделение:\n",
      "Train: 229 документов\n",
      "Validation: 78 документов\n",
      "Train окон: 7825 (80.0%)\n",
      "Validation окон: 1960 (20.0%)\n",
      "\n",
      "Проверка на утечку: Всё хорошо\n",
      "Размер validation датасета: 1960 окон\n",
      "\n",
      "МЕТРИКИ ПО КЛАССАМ:\n",
      "   Сущность  Precision  Recall  F1-Score  Support\n",
      "          O     0.9932  0.9936    0.9934   411595\n",
      "    I-LINKS     0.9880  0.9938    0.9909    24818\n",
      "     I-TIME     0.9848  0.9907    0.9877    15313\n",
      "    B-LINKS     0.9718  0.9769    0.9744     1906\n",
      "     B-TIME     0.9627  0.9795    0.9710     4242\n",
      "   B-DEGREE     0.9496  0.9720    0.9606      678\n",
      "   I-DEGREE     0.9246  0.9538    0.9390     1774\n",
      " B-LOCATION     0.9277  0.9362    0.9320     2070\n",
      " I-LOCATION     0.9428  0.8927    0.9171     1864\n",
      "B-POSITIONS     0.9121  0.9029    0.9075     2265\n",
      "I-POSITIONS     0.9158  0.8752    0.8950    10850\n",
      "  I-METRICS     0.7545  0.7476    0.7510     2080\n",
      "  B-METRICS     0.6860  0.7065    0.6961      569\n",
      "\n",
      "Результаты сохранены в validation_metrics_group1.csv\n",
      "\n",
      "Оценка модели group2...\n",
      "Модель: /Users/artemzmailov/Desktop/NER_IT_Resumes_Project/models/model_2_final\n",
      "Датасет: /Users/artemzmailov/Desktop/NER_IT_Resumes_Project/datasets/group2_dataset.jsonl\n",
      "Подготовка данных с перекрывающимися окнами...\n",
      "Загружено 307 предложений из JSONL файла\n",
      "Загружено 307 исходных документов\n",
      "Найдено 7 меток: ['O', 'B-COMPANIES', 'B-NAME', 'B-TECHNOLOGIES', 'I-COMPANIES', 'I-NAME', 'I-TECHNOLOGIES']\n",
      "\n",
      "Статистика по окнам:\n",
      "Всего окон: 9786\n",
      "Среднее число окон на документ: 31.9\n",
      "Мин/макс окон на документ: 1 / 366\n",
      "\n",
      "Целевой размер валидации: 1957 окон (20%)\n",
      "\n",
      "Итоговое разделение:\n",
      "Train: 229 документов\n",
      "Validation: 78 документов\n",
      "Train окон: 7827 (80.0%)\n",
      "Validation окон: 1959 (20.0%)\n",
      "\n",
      "Проверка на утечку: Всё хорошо\n",
      "Размер validation датасета: 1959 окон\n",
      "\n",
      "МЕТРИКИ ПО КЛАССАМ:\n",
      "      Сущность  Precision  Recall  F1-Score  Support\n",
      "             O     0.9880  0.9859    0.9870   421128\n",
      "B-TECHNOLOGIES     0.9100  0.9347    0.9222    16244\n",
      "I-TECHNOLOGIES     0.8771  0.8927    0.8848    26416\n",
      "   I-COMPANIES     0.8724  0.8687    0.8705    12905\n",
      "        I-NAME     0.8155  0.8893    0.8508      497\n",
      "   B-COMPANIES     0.8187  0.8193    0.8190     2601\n",
      "        B-NAME     0.7651  0.8702    0.8143      131\n",
      "\n",
      "Результаты сохранены в validation_metrics_group2.csv\n",
      "\n",
      "Оценка модели group3...\n",
      "Модель: /Users/artemzmailov/Desktop/NER_IT_Resumes_Project/models/model_3_final\n",
      "Датасет: /Users/artemzmailov/Desktop/NER_IT_Resumes_Project/datasets/group3_dataset.jsonl\n",
      "Подготовка данных с перекрывающимися окнами...\n",
      "Загружено 307 предложений из JSONL файла\n",
      "Загружено 307 исходных документов\n",
      "Найдено 13 меток: ['O', 'B-ACHIEVEMENTS', 'B-CONTACTS', 'B-EDUCATION', 'B-PROJECTS', 'B-RESPONSIBILITIES', 'B-SKILLS', 'I-ACHIEVEMENTS', 'I-CONTACTS', 'I-EDUCATION', 'I-PROJECTS', 'I-RESPONSIBILITIES', 'I-SKILLS']\n",
      "\n",
      "Статистика по окнам:\n",
      "Всего окон: 9787\n",
      "Среднее число окон на документ: 31.9\n",
      "Мин/макс окон на документ: 1 / 366\n",
      "\n",
      "Целевой размер валидации: 1957 окон (20%)\n",
      "\n",
      "Итоговое разделение:\n",
      "Train: 229 документов\n",
      "Validation: 78 документов\n",
      "Train окон: 7827 (80.0%)\n",
      "Validation окон: 1960 (20.0%)\n",
      "\n",
      "Проверка на утечку: Всё хорошо\n",
      "Размер validation датасета: 1960 окон\n",
      "\n",
      "МЕТРИКИ ПО КЛАССАМ:\n",
      "          Сущность  Precision  Recall  F1-Score  Support\n",
      "       I-EDUCATION     0.8956  0.8900    0.8928    18114\n",
      "                 O     0.8715  0.9102    0.8905   201816\n",
      "       B-EDUCATION     0.8721  0.8612    0.8666     1354\n",
      "I-RESPONSIBILITIES     0.8654  0.8554    0.8604   150101\n",
      "B-RESPONSIBILITIES     0.8067  0.8414    0.8237     8096\n",
      "    B-ACHIEVEMENTS     0.7029  0.6941    0.6984     1847\n",
      "    I-ACHIEVEMENTS     0.7076  0.6825    0.6948    49959\n",
      "        B-CONTACTS     0.8455  0.5778    0.6865      180\n",
      "          I-SKILLS     0.6476  0.6863    0.6664    11841\n",
      "        I-CONTACTS     0.7738  0.5763    0.6606     3212\n",
      "          B-SKILLS     0.6449  0.6380    0.6414     1036\n",
      "        I-PROJECTS     0.6636  0.5468    0.5995    31105\n",
      "        B-PROJECTS     0.5889  0.5932    0.5910     1357\n",
      "\n",
      "Результаты сохранены в validation_metrics_group3.csv\n",
      "\n",
      "================================================================================\n",
      "Сводная таблица по всем моделям\n",
      "================================================================================\n",
      "Модель Macro F1 Weighted F1  Всего классов\n",
      "group1   0.9102      0.9880             13\n",
      "group2   0.8603      0.9749              7\n",
      "group3   0.7235      0.8315             13\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, DataCollatorForTokenClassification\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Конфигурация\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "WINDOW_SIZE = 510\n",
    "STRIDE = 64\n",
    "BASE_PATH = Path(\"/Users/artemzmailov/Desktop/NER_IT_Resumes_Project\")\n",
    "\n",
    "print(f\" Устройство: {DEVICE}\")\n",
    "\n",
    "def evaluate_validation_set(model_path, dataset_path, tokenizer, group_name, output_directory = ''):\n",
    "    \"\"\"\n",
    "    Оценивает модель на validation датасете (20% документов)\n",
    "    \"\"\"\n",
    "    print(f\"\\nОценка модели {group_name}...\")\n",
    "    print(f\"Модель: {model_path}\")\n",
    "    print(f\"Датасет: {dataset_path}\")\n",
    "    \n",
    "    # Загружаем модель\n",
    "    model = AutoModelForTokenClassification.from_pretrained(str(model_path))\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    # Подготавливаем датасет \n",
    "    dataset, label2id, id2label, label_list = prepare_dataset_with_sliding_windows(\n",
    "        str(dataset_path), tokenizer, \n",
    "        window_size=WINDOW_SIZE, \n",
    "        stride=STRIDE, \n",
    "        val_fraction=0.2\n",
    "    )\n",
    "    \n",
    "    val_dataset = dataset['validation']\n",
    "    print(f\"Размер validation датасета: {len(val_dataset)} окон\")\n",
    "    \n",
    "    # DataLoader\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=16, \n",
    "        collate_fn=data_collator,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Собираем предсказания\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch in val_dataloader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        \n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        mask = batch['labels'] != -100\n",
    "        \n",
    "        all_predictions.extend(predictions[mask].cpu().numpy())\n",
    "        all_labels.extend(batch['labels'][mask].cpu().numpy())\n",
    "    \n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Метрики по классам\n",
    "    labels_list = list(id2label.keys())\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        all_labels, all_predictions, labels=labels_list, average=None\n",
    "    )\n",
    "    \n",
    "    # DataFrame\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Сущность': [id2label[i] for i in labels_list],\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Support': support\n",
    "    })\n",
    "    \n",
    "    # Сортируем по F1\n",
    "    metrics_df = metrics_df.sort_values('F1-Score', ascending=False)\n",
    "    \n",
    "    print(\"\\nМЕТРИКИ ПО КЛАССАМ:\")\n",
    "    print(metrics_df.round(4).to_string(index=False))\n",
    "    \n",
    "    # Сохраняем\n",
    "    output_file = output_directory + f\"validation_metrics_{group_name}.csv\"\n",
    "    metrics_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"\\nРезультаты сохранены в {output_file}\")\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# Запуск\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Gherman/bert-base-NER-Russian\")\n",
    "    \n",
    "    models_config = [\n",
    "        {\n",
    "            'group': 'group1',\n",
    "            'model_path': BASE_PATH / 'models' / 'model_1_final',\n",
    "            'dataset_path': BASE_PATH / 'datasets' / 'group1_dataset.jsonl'\n",
    "        },\n",
    "        {\n",
    "            'group': 'group2',\n",
    "            'model_path': BASE_PATH / 'models' / 'model_2_final',\n",
    "            'dataset_path': BASE_PATH / 'datasets' / 'group2_dataset.jsonl'\n",
    "        },\n",
    "        {\n",
    "            'group': 'group3',\n",
    "            'model_path': BASE_PATH / 'models' / 'model_3_final',\n",
    "            'dataset_path': BASE_PATH / 'datasets' / 'group3_dataset.jsonl'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    all_results = {}\n",
    "    for config in models_config:\n",
    "        try:\n",
    "            metrics = evaluate_validation_set(\n",
    "                model_path=config['model_path'],\n",
    "                dataset_path=config['dataset_path'],\n",
    "                tokenizer=tokenizer,\n",
    "                group_name=config['group']\n",
    "            )\n",
    "            all_results[config['group']] = metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке {config['group']}: {e}\")\n",
    "    \n",
    "    # Сводная таблица\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Сводная таблица по всем моделям\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    summary = []\n",
    "    for group, df in all_results.items():\n",
    "        entity_metrics = df[df['Сущность'] != 'O']\n",
    "        summary.append({\n",
    "            'Модель': group,\n",
    "            'Macro F1': f\"{entity_metrics['F1-Score'].mean():.4f}\",\n",
    "            'Weighted F1': f\"{(df['F1-Score'] * df['Support']).sum() / df['Support'].sum():.4f}\",\n",
    "            'Всего классов': len(df)\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ebfed-ecb2-4387-aa9b-14784992f596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
